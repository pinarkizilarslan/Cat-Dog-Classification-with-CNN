{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c724d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator kütüphanesi resimleri toplu olarak değil de sırayla yükleyerek belleğin daha iyi çalışmasını sağlar.\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938e4681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versiyon kontrol edilir.\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ac1591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Eğitim setinin ön işlenmesi\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('../dataset/training_set',\n",
    "                                                target_size = (64,64), #hedef boyutu 64x64 piksel\n",
    "                                                batch_size = 32, #bu değerin büyük olması daha doğru gradient değeri hesaplamasını sağlar\n",
    "                                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd8c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test setinin ön işlenmesi\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('../dataset/test_set',\n",
    "                                                target_size = (64,64),\n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4177fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN mimarisi oluşturuluyor\n",
    "\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698c23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 1 : Convolution\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))\n",
    "\n",
    "# Gizli katmanlar arasında relu aktivasyon fonksiyonu kullanılıyor.\n",
    "# Conv2D fonksiyonu sayesinde datalar 64x64 boyutunda ele alınacak.\n",
    "# input_shape deki 3 parametresi ise resimler renkli olduğu için 3 adet katman oluşturulacak.\n",
    "# Bu katmanlar kırmızı, yeşil ve mavi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7145522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 2 : Pooling\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# Pooling işlemi için MaxPool yöntemi kullanılacaktır.\n",
    "# strides yani adım sayısı 2 olarak belirlenmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926f6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 3 : İkinci Convolution Katmanı ve İkinci Pooling İşlemi\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) # Convolution\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) # Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c10ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 4 : Flattening\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Gelen veriler üzerinde flatting işlemi yapılıyor\n",
    "# Bu, verilerin yapay sinir ağına gelmeden hemen önce düzleştirilmesidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e769d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 5 : Full Connection\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Burda NN deki gizli katmanlar ve nöronlar oluşturulur.\n",
    "# Kaç katman olacağı units metodu ile 128 olarak belirlenmiştir. Sebebi resimlerin 64x64 boyutunda olmasıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "476ea5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adım 6 : Çıkış Katmanı\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Çıkış katmanında sınıflandırma yapılacağı için sigmoid kullanılmıştır.\n",
    "# Çıktı 1 olarak çıkarsa dog, 0 olarak çıkarsa cat dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a4420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile (Derleme) İşlemi\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "769b5648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "266/266 [==============================] - 79s 291ms/step - loss: 0.6178 - accuracy: 0.6439 - val_loss: 0.7364 - val_accuracy: 0.6510\n",
      "Epoch 2/45\n",
      "266/266 [==============================] - 85s 319ms/step - loss: 0.5216 - accuracy: 0.7411 - val_loss: 0.5254 - val_accuracy: 0.7390\n",
      "Epoch 3/45\n",
      "266/266 [==============================] - 81s 306ms/step - loss: 0.4867 - accuracy: 0.7651 - val_loss: 0.4903 - val_accuracy: 0.7670\n",
      "Epoch 4/45\n",
      "266/266 [==============================] - 69s 261ms/step - loss: 0.4562 - accuracy: 0.7816 - val_loss: 0.4603 - val_accuracy: 0.7810\n",
      "Epoch 5/45\n",
      "266/266 [==============================] - 73s 276ms/step - loss: 0.4402 - accuracy: 0.7952 - val_loss: 0.5094 - val_accuracy: 0.7640\n",
      "Epoch 6/45\n",
      "266/266 [==============================] - 84s 317ms/step - loss: 0.4243 - accuracy: 0.7973 - val_loss: 0.4861 - val_accuracy: 0.7830\n",
      "Epoch 7/45\n",
      "266/266 [==============================] - 90s 339ms/step - loss: 0.4180 - accuracy: 0.8042 - val_loss: 0.4975 - val_accuracy: 0.7760\n",
      "Epoch 8/45\n",
      "266/266 [==============================] - 101s 380ms/step - loss: 0.4022 - accuracy: 0.8148 - val_loss: 0.4111 - val_accuracy: 0.8110\n",
      "Epoch 9/45\n",
      "266/266 [==============================] - 107s 401ms/step - loss: 0.3892 - accuracy: 0.8222 - val_loss: 0.5073 - val_accuracy: 0.7520\n",
      "Epoch 10/45\n",
      "266/266 [==============================] - 110s 412ms/step - loss: 0.3827 - accuracy: 0.8255 - val_loss: 0.5508 - val_accuracy: 0.7400\n",
      "Epoch 11/45\n",
      "266/266 [==============================] - 107s 402ms/step - loss: 0.3717 - accuracy: 0.8341 - val_loss: 0.3932 - val_accuracy: 0.8280\n",
      "Epoch 12/45\n",
      "266/266 [==============================] - 88s 330ms/step - loss: 0.3612 - accuracy: 0.8428 - val_loss: 0.4417 - val_accuracy: 0.8070\n",
      "Epoch 13/45\n",
      "266/266 [==============================] - 82s 307ms/step - loss: 0.3328 - accuracy: 0.8565 - val_loss: 0.4443 - val_accuracy: 0.7950\n",
      "Epoch 14/45\n",
      "266/266 [==============================] - 106s 398ms/step - loss: 0.3343 - accuracy: 0.8509 - val_loss: 0.5561 - val_accuracy: 0.7420\n",
      "Epoch 15/45\n",
      "266/266 [==============================] - 117s 439ms/step - loss: 0.3178 - accuracy: 0.8655 - val_loss: 0.5176 - val_accuracy: 0.7730\n",
      "Epoch 16/45\n",
      "266/266 [==============================] - 93s 351ms/step - loss: 0.3045 - accuracy: 0.8652 - val_loss: 0.4796 - val_accuracy: 0.8080\n",
      "Epoch 17/45\n",
      "266/266 [==============================] - 95s 357ms/step - loss: 0.3107 - accuracy: 0.8658 - val_loss: 0.5184 - val_accuracy: 0.7810\n",
      "Epoch 18/45\n",
      "266/266 [==============================] - 93s 350ms/step - loss: 0.2802 - accuracy: 0.8784 - val_loss: 0.6850 - val_accuracy: 0.7530\n",
      "Epoch 19/45\n",
      "266/266 [==============================] - 76s 286ms/step - loss: 0.2785 - accuracy: 0.8784 - val_loss: 0.8548 - val_accuracy: 0.6820\n",
      "Epoch 20/45\n",
      "266/266 [==============================] - 104s 392ms/step - loss: 0.2621 - accuracy: 0.8884 - val_loss: 0.6643 - val_accuracy: 0.7340\n",
      "Epoch 21/45\n",
      "266/266 [==============================] - 104s 391ms/step - loss: 0.2538 - accuracy: 0.8894 - val_loss: 0.5370 - val_accuracy: 0.7730\n",
      "Epoch 22/45\n",
      "266/266 [==============================] - 95s 357ms/step - loss: 0.2379 - accuracy: 0.8985 - val_loss: 0.4719 - val_accuracy: 0.8070\n",
      "Epoch 23/45\n",
      "266/266 [==============================] - 80s 298ms/step - loss: 0.2369 - accuracy: 0.9002 - val_loss: 0.4881 - val_accuracy: 0.8240\n",
      "Epoch 24/45\n",
      "266/266 [==============================] - 82s 306ms/step - loss: 0.2202 - accuracy: 0.9098 - val_loss: 0.6014 - val_accuracy: 0.7870\n",
      "Epoch 25/45\n",
      "266/266 [==============================] - 68s 254ms/step - loss: 0.2049 - accuracy: 0.9181 - val_loss: 0.5681 - val_accuracy: 0.7930\n",
      "Epoch 26/45\n",
      "266/266 [==============================] - 73s 275ms/step - loss: 0.1921 - accuracy: 0.9218 - val_loss: 0.7511 - val_accuracy: 0.7700\n",
      "Epoch 27/45\n",
      "266/266 [==============================] - 82s 307ms/step - loss: 0.1980 - accuracy: 0.9218 - val_loss: 0.4954 - val_accuracy: 0.8140\n",
      "Epoch 28/45\n",
      "266/266 [==============================] - 68s 257ms/step - loss: 0.1759 - accuracy: 0.9316 - val_loss: 0.5906 - val_accuracy: 0.8040\n",
      "Epoch 29/45\n",
      "266/266 [==============================] - 76s 286ms/step - loss: 0.1740 - accuracy: 0.9292 - val_loss: 0.6399 - val_accuracy: 0.7860\n",
      "Epoch 30/45\n",
      "266/266 [==============================] - 65s 244ms/step - loss: 0.1708 - accuracy: 0.9346 - val_loss: 0.5936 - val_accuracy: 0.7940\n",
      "Epoch 31/45\n",
      "266/266 [==============================] - 74s 279ms/step - loss: 0.1475 - accuracy: 0.9407 - val_loss: 0.8166 - val_accuracy: 0.7700\n",
      "Epoch 32/45\n",
      "266/266 [==============================] - 71s 268ms/step - loss: 0.1598 - accuracy: 0.9378 - val_loss: 0.5225 - val_accuracy: 0.8200\n",
      "Epoch 33/45\n",
      "266/266 [==============================] - 68s 255ms/step - loss: 0.1455 - accuracy: 0.9425 - val_loss: 0.5479 - val_accuracy: 0.8330\n",
      "Epoch 34/45\n",
      "266/266 [==============================] - 79s 297ms/step - loss: 0.1455 - accuracy: 0.9438 - val_loss: 0.7868 - val_accuracy: 0.7800\n",
      "Epoch 35/45\n",
      "266/266 [==============================] - 78s 294ms/step - loss: 0.1423 - accuracy: 0.9478 - val_loss: 0.8025 - val_accuracy: 0.7740\n",
      "Epoch 36/45\n",
      "266/266 [==============================] - 87s 327ms/step - loss: 0.1262 - accuracy: 0.9499 - val_loss: 0.6008 - val_accuracy: 0.8260\n",
      "Epoch 37/45\n",
      "266/266 [==============================] - 82s 306ms/step - loss: 0.1245 - accuracy: 0.9512 - val_loss: 0.6462 - val_accuracy: 0.8100\n",
      "Epoch 38/45\n",
      "266/266 [==============================] - 92s 347ms/step - loss: 0.1212 - accuracy: 0.9541 - val_loss: 0.8525 - val_accuracy: 0.7840\n",
      "Epoch 39/45\n",
      "266/266 [==============================] - 74s 280ms/step - loss: 0.1162 - accuracy: 0.9573 - val_loss: 0.9406 - val_accuracy: 0.7690\n",
      "Epoch 40/45\n",
      "266/266 [==============================] - 83s 311ms/step - loss: 0.1146 - accuracy: 0.9579 - val_loss: 0.8447 - val_accuracy: 0.7740\n",
      "Epoch 41/45\n",
      "266/266 [==============================] - 85s 321ms/step - loss: 0.1075 - accuracy: 0.9589 - val_loss: 0.6727 - val_accuracy: 0.8100\n",
      "Epoch 42/45\n",
      "266/266 [==============================] - 87s 326ms/step - loss: 0.1069 - accuracy: 0.9601 - val_loss: 1.0282 - val_accuracy: 0.7750\n",
      "Epoch 43/45\n",
      "266/266 [==============================] - 88s 332ms/step - loss: 0.0893 - accuracy: 0.9667 - val_loss: 0.8021 - val_accuracy: 0.8040\n",
      "Epoch 44/45\n",
      "266/266 [==============================] - 78s 292ms/step - loss: 0.1036 - accuracy: 0.9598 - val_loss: 0.7109 - val_accuracy: 0.8090\n",
      "Epoch 45/45\n",
      "266/266 [==============================] - 76s 284ms/step - loss: 0.0880 - accuracy: 0.9658 - val_loss: 0.8164 - val_accuracy: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9d5c7e970>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eğitim işlemi\n",
    "\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=45)\n",
    "\n",
    "# epochs değeri ile 45 adımda öğrenme işlemi yapacak.\n",
    "# Bu sayıdan başka sayılar da denenmiş ve accuary değerinin 1'e en yakın olduğu sonuç epochs=50 ile bulunmuştur.\n",
    "# Daha fazla olduğunda ise ezberleme yöntemine gittiği görülmüştür.\n",
    "# Aktivasyon fonksiyonunun katsayılarını her seferinde güncelleyecek.\n",
    "\n",
    "# Eğitim sırasından accuracy değeri düşük başlayacaktır yaklaşık %50 gibi\n",
    "# Veri seti incelendikçe ve loss fonksiyonu ile tekrar katsayıları güncelledikçe accuracy değeri yükselecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fa21440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "# Tahmin Oluşturma\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Aşağıdaki single_prediction/ altına atılan resimler manuel olarak test edilebilir, isimlendirmeyi değiştirmek yeterlidir.\n",
    "\n",
    "test_image = keras.utils.load_img('../dataset/single_prediction/8.jpg', target_size=(64, 64))\n",
    "test_image = keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0]==1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "066a2b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "# Sonuç\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d8194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
